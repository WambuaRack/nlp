{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_csv('Sheet_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>response_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flagged</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flagged</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Now that I've been through it, although i'm no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>flagged</td>\n",
       "      <td>when my best friends mom past away from od'ing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>As a camp counselor I provide stability in kid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>flagged</td>\n",
       "      <td>My now girlfriend used to have serious addicti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>not_flagged</td>\n",
       "      <td>The one person I ever talked to it was because...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          class                                      response_text\n",
       "0   not_flagged              I try and avoid this sort of conflict\n",
       "1       flagged  Had a friend open up to me about his mental ad...\n",
       "2       flagged  I saved a girl from suicide once. She was goin...\n",
       "3   not_flagged  i cant think of one really...i think i may hav...\n",
       "4   not_flagged  Only really one friend who doesn't fit into th...\n",
       "..          ...                                                ...\n",
       "75  not_flagged  Now that I've been through it, although i'm no...\n",
       "76      flagged  when my best friends mom past away from od'ing...\n",
       "77  not_flagged  As a camp counselor I provide stability in kid...\n",
       "78      flagged  My now girlfriend used to have serious addicti...\n",
       "79  not_flagged  The one person I ever talked to it was because...\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data[\"class\"],data[\"response_text\"]], axis = 1)\n",
    "# Sheet_1.drop([\"response_id\",\"Unnamed: 3\",\"Unnamed: 4\",\"Unnamed: 5\",\"Unnamed: 6\",\"Unnamed: 7\"], axis = 1, inplace = True)\n",
    "\n",
    "data.dropna(axis = 0, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class'] = data['class'].map({'not_flagged':0, 'flagged':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class            0\n",
       "response_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80 entries, 0 to 79\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   class          80 non-null     int64 \n",
      " 1   response_text  80 non-null     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Only really one friend who doesn\\'t fit into the any of the above categories. Her therapist calls it spiraling.\" Anyway she pretty much calls me any time she is frustrated by something with  her boyfriend to ask me if it\\'s logical or not. Before they would just fight and he would call her crazy. Now she asks me if it\\'s ok he didn\\'t say \"please\" when he said  \"hand me the remote.\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets apply on one series aggrgate,tokenization, stopwords, lemmatazation\n",
    "data['response_text'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'only really one friend who doesn t fit into the any of the above categories  her therapist calls it spiraling   anyway she pretty much calls me any time she is frustrated by something with  her boyfriend to ask me if it s logical or not  before they would just fight and he would call her crazy  now she asks me if it s ok he didn t say  please  when he said   hand me the remote  '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "first_Res_text = data['response_text'][4]\n",
    "Res_text = re.sub(\"[^a-zA-Z]\",\" \", first_Res_text).lower()\n",
    "Res_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "Res_text = nltk.word_tokenize(Res_text)\n",
    "Res_text = [word for word in Res_text if not word in set(stopwords.words('english'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shedr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\shedr\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "Res_text = [lemma.lemmatize(word) for word in Res_text]\n",
    "Res_text = \" \".join(Res_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as nlp\n",
    "description_list = [] # List\n",
    "for description in data.response_text:\n",
    "       \n",
    "    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n",
    "    description = description.lower() \n",
    "    \n",
    "    description = nltk.word_tokenize(description)\n",
    "    description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\n",
    "    \n",
    "    lemma = nlp.WordNetLemmatizer()\n",
    "    description = [ lemma.lemmatize(word) for word in description]\n",
    "    \n",
    "    description = \" \".join(description)\n",
    "    description_list.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequently used 500 words ['able' 'absolutely' 'acquaintance' 'acted' 'action' 'activity'\n",
      " 'addiction' 'adequate' 'admit' 'advice' 'advise' 'age' 'ago' 'agony'\n",
      " 'alcoholic' 'allowed' 'anniversary' 'answer' 'anxiety' 'anxious'\n",
      " 'apposed' 'ask' 'asks' 'attention' 'aunt' 'avoid' 'away' 'bad'\n",
      " 'basically' 'bedroom' 'best' 'better' 'big' 'bit' 'blow' 'blue' 'blunt'\n",
      " 'book' 'boyfriend' 'break' 'bring' 'brother' 'brought' 'bunch' 'called'\n",
      " 'calling' 'calm' 'came' 'camp' 'camping' 'campsite' 'cancer' 'car' 'care'\n",
      " 'caring' 'category' 'caught' 'cause' 'chance' 'change' 'changed' 'chat'\n",
      " 'circumstance' 'clean' 'cleaning' 'cocaine' 'come' 'comfort' 'comforted'\n",
      " 'commit' 'common' 'complete' 'completely' 'concern' 'confines' 'conflict'\n",
      " 'convinced' 'cop' 'cope' 'counselor' 'countless' 'couple' 'crazy'\n",
      " 'cutter' 'cutting' 'damn' 'dating' 'day' 'dealing' 'dealt' 'death'\n",
      " 'defined' 'depressed' 'depression' 'describes' 'desire' 'diagnosed'\n",
      " 'dialog' 'difficulty' 'disorder' 'doc' 'dont' 'douche' 'drag' 'drove'\n",
      " 'drug' 'dump' 'dumped' 'dying' 'ear' 'earlier' 'email' 'emotional'\n",
      " 'encourage' 'end' 'ended' 'entire' 'essential' 'esteem' 'eventually'\n",
      " 'everyday' 'ex' 'example' 'excited' 'experience' 'express' 'expressing'\n",
      " 'extremely' 'face' 'facebook' 'faced' 'facing' 'fact' 'fairly' 'family'\n",
      " 'father' 'feel' 'feeling' 'fell' 'felt' 'fight' 'fit' 'fixed' 'flicker'\n",
      " 'focus' 'friend' 'frustrated' 'gave' 'ged' 'gf' 'girl' 'girlfriend'\n",
      " 'giving' 'goal' 'going' 'gone' 'good' 'got' 'grade' 'grandmother' 'guess'\n",
      " 'guy' 'hadnt' 'haha' 'half' 'hand' 'happens' 'hard' 'harmed' 'head'\n",
      " 'healing' 'health' 'hear' 'heard' 'help' 'helped' 'helpful' 'helping'\n",
      " 'hesitate' 'high' 'hit' 'hold' 'home' 'homeless' 'honest' 'hood' 'hope'\n",
      " 'hoping' 'horrable' 'hospital' 'hour' 'house' 'huge' 'human' 'hung'\n",
      " 'hurt' 'idk' 'important' 'indirectly' 'ing' 'initiated' 'innermost'\n",
      " 'input' 'inside' 'intense' 'internet' 'irl' 'isolated' 'issue' 'jokingly'\n",
      " 'judge' 'junior' 'kid' 'kill' 'killed' 'kind' 'kindness' 'knew' 'know'\n",
      " 'knowledge' 'known' 'lack' 'late' 'laugh' 'le' 'lent' 'let' 'letting'\n",
      " 'level' 'life' 'light' 'like' 'line' 'listen' 'listened' 'listener'\n",
      " 'listening' 'little' 'living' 'logical' 'long' 'look' 'looked' 'losing'\n",
      " 'loss' 'lost' 'lot' 'loving' 'low' 'major' 'make' 'making' 'managed'\n",
      " 'maybe' 'memorial' 'men' 'mental' 'met' 'method' 'mind' 'mom' 'month'\n",
      " 'mother' 'mt' 'nah' 'naturally' 'necessarily' 'need' 'needed' 'nervous'\n",
      " 'nice' 'night' 'normal' 'number' 'objective' 'obtain' 'occurrence' 'od'\n",
      " 'offer' 'offered' 'oh' 'ok' 'open' 'openness' 'overcome' 'packed'\n",
      " 'parent' 'past' 'path' 'peace' 'people' 'perfect' 'period' 'person'\n",
      " 'personal' 'physical' 'picked' 'pill' 'positive' 'possible' 'possibly'\n",
      " 'pretty' 'probably' 'problem' 'progress' 'promised' 'provide' 'psych'\n",
      " 'pulled' 'purpose' 'qualified' 'question' 'quite' 'rant' 'rational'\n",
      " 'reading' 'reality' 'realize' 'really' 'recovery' 'refers' 'reflect'\n",
      " 'rehab' 'rejected' 'rejecting' 'relate' 'related' 'relationship' 'relief'\n",
      " 'remember' 'remind' 'remote' 'resource' 'respect' 'restless' 'result'\n",
      " 'roommate' 'rude' 'sad' 'said' 'saved' 'saw' 'say' 'saying' 'school'\n",
      " 'schoolwork' 'self' 'sense' 'set' 'severe' 'share' 'shared' 'sharing'\n",
      " 'shelter' 'shit' 'shortly' 'sign' 'similar' 'simply' 'sister' 'situation'\n",
      " 'skipped' 'slightly' 'slowly' 'somebody' 'sort' 'speak' 'specific'\n",
      " 'specifically' 'spent' 'spiraling' 'spot' 'stability' 'start' 'started'\n",
      " 'stayed' 'stopped' 'story' 'stranger' 'struggle' 'struggling' 'stuff'\n",
      " 'subject' 'suffer' 'suicidal' 'suicide' 'summer' 'super' 'support'\n",
      " 'supporting' 'supportive' 'sure' 'surfing' 'survival' 'sustained'\n",
      " 'swallow' 'swaying' 'swimming' 'switch' 'switched' 'taken' 'taking'\n",
      " 'talk' 'talked' 'talking' 'teacher' 'tell' 'telling' 'thankgiving'\n",
      " 'thats' 'therapist' 'therapy' 'theripist' 'thing' 'think' 'thinking'\n",
      " 'thought' 'threw' 'till' 'time' 'told' 'took' 'tough' 'trapped' 'treat'\n",
      " 'treatment' 'tried' 'trouble' 'troubled' 'truth' 'try' 'tryin' 'trying'\n",
      " 'tunnel' 'turmoil' 'tutor' 'twice' 'type' 'understand' 'unfortunately'\n",
      " 'unless' 'used' 'using' 'vent' 'verge' 'virgity' 'visited' 'walked'\n",
      " 'want' 'wanted' 'ward' 'way' 'weed' 'week' 'went' 'wood' 'work' 'worked'\n",
      " 'write' 'year' 'yearbook']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "max_feature = 500\n",
    "\n",
    "cv = CountVectorizer(max_features = max_feature, stop_words = \"english\")\n",
    "\n",
    "space_matrix = cv.fit_transform(description_list).toarray() # x\n",
    "\n",
    "print(\"Most frequently used {} words {}\".format(max_feature, cv.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = space_matrix\n",
    "y = data.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Random Forest is 0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(x_train,y_train)\n",
    "\n",
    "y_pred = gnb.predict(x_test)\n",
    "\n",
    "print('The accuracy of the Random Forest is',metrics.accuracy_score(y_pred,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
